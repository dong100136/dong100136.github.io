<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="大数据小菜鸟一枚"><title>kmeans和som的简单比较 | Stone 东少</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">kmeans和som的简单比较</h1><a id="logo" href="/.">Stone 东少</a><p class="description">知足，常乐</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="https://dong100136.github.io/PracticeCode/"><i class="fa fa-code"> 小代码</i></a><a href="/resume"><i class="fa fa-sticky-note"> resume</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">kmeans和som的简单比较</h1><div class="post-meta">Nov 26, 2017<script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><div class="post-content"><p>聚类分析是一种常用的分析方法，其中最为常用的 KMeans。最近也看到一个KMeans 的改进方法，是加入 som 竞争神经网络进行训练。</p>
<p>竞争神经网络是一个仿照人脑神经元的启发而发明的，在这个神经网络中，神经元竞争被激活的机会。当接受到刺激的时候，神经网络中的一部分神经元会兴奋，而其他的则不会。此类神经元会对某类特征特别敏感。<br>整个神经元中，不同的神经元对不同的特征敏感。兴奋的神经元会对周围的神经元起抑制作用。</p>
<p>此次比较使用了三组数据，分别是经典的 iris 数据集，和随机生成的两个圆。iris 数据集可以近似看做线性可分，两个圆的就是线性不可分的情况。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</div><div class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</div><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</div><div class="line">iris = load_iris()</div><div class="line">labels = KMeans(n_clusters=<span class="number">3</span>).fit_predict(iris.data)</div><div class="line">print(classification_report(iris.target,labels))</div><div class="line">plt.scatter(iris_reduce[:,<span class="number">0</span>],iris_reduce[:,<span class="number">1</span>],c=labels)</div></pre></td></tr></table></figure>
<p><img src="https://user-images.githubusercontent.com/10239202/33238090-86f2bfe0-d2c0-11e7-86de-200ede82fe4b.png" alt="image"></p>
<p>f1得分为0.89</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">def som(k,x,y,data):</div><div class="line">    # k 为簇数，x,y为神经网络的形状</div><div class="line">    som = MiniSom(x,y,data.shape[1],sigma=1,learning_rate=0.5)</div><div class="line">    som.random_weights_init(np.array(data))</div><div class="line">    som.train_random(np.array(data),2000)</div><div class="line">    </div><div class="line">    w = som.get_weights()</div><div class="line">    weight = pd.DataFrame(w.reshape(x*y,data.shape[1]))</div><div class="line">    KM =KMeans(n_clusters=k,n_jobs=-1)</div><div class="line">    model = KM.fit(weight)</div><div class="line">    weight[&apos;label&apos;] = model.labels_</div><div class="line">    rs = np.array(weight[&apos;label&apos;]).reshape((x,y))</div><div class="line"></div><div class="line">    def get_winner(v):</div><div class="line">        l = som.winner(np.array(v))</div><div class="line">        return rs[l]</div><div class="line">    </div><div class="line">    return pd.DataFrame(data).apply(get_winner,axis=1)</div><div class="line"></div><div class="line">labels2 = som(3,20,20,iris.data)</div></pre></td></tr></table></figure>
<p><img src="https://user-images.githubusercontent.com/10239202/33238109-f10ede68-d2c0-11e7-99c3-3ea4f6384d5d.png" alt="image"></p>
<p>f1得分为0.95</p>
<p>可以看出 som 这种方法可以获得比 kmeans 稍好的结果。</p>
<p>下面看看线性不可分的情况，使用 sklearn 里面的 make_circle来生成数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">from sklearn.datasets import make_circles</div><div class="line">x, label = make_circles(n_samples=400, factor=.3, noise=.05)</div><div class="line">plt.scatter(x[:,0],x[:,1],c=label)</div></pre></td></tr></table></figure>
<p><img src="https://user-images.githubusercontent.com/10239202/33238133-89438dd2-d2c1-11e7-8620-9e0a94e4e347.png" alt="image"></p>
<p>下面分别是 kmeans 和 som 的结果：</p>
<p><img src="https://user-images.githubusercontent.com/10239202/33238136-ab82db46-d2c1-11e7-9175-22f987259a82.png" alt="image"></p>
<p><img src="https://user-images.githubusercontent.com/10239202/33238141-b090019a-d2c1-11e7-8d18-004ba6e1feb7.png" alt="image"></p>
<p>可以看出两个聚类器都不能识别这类情况，所以我感觉 som 只能对线性可分的情况进行处理，而且总体上和 kmeans 差不多，也没有特别不一样。</p>
<p>在处理线性不可分的这个情况，又试了一下 DBSCAN 和 KernelPCA。</p>
<p>DBSCAN 是一种基于密度的聚类方法，可以发现一些不规则的簇。但是它使用的范围其实很有限，如果分类的点的密度不均衡，则会出现问题，另外对于<br>较高维度的数据，同样不是很适合。</p>
<p>PCA 主成分分析是进行降维的，而 KPCA 则恰恰相反，通过核函数，进行升维，将原来线性不可分的问题转换为线性可分的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> DBSCAN</div><div class="line">model= DBSCAN(eps=<span class="number">.1</span>,min_samples=<span class="number">10</span>)</div><div class="line">label_dbscan = model.fit_predict(x)</div><div class="line">plt.scatter(x[:,<span class="number">0</span>],x[:,<span class="number">1</span>],c=label_dbscan)</div><div class="line">print(classification_report(label,label_dbscan))</div></pre></td></tr></table></figure>
<p><img src="https://user-images.githubusercontent.com/10239202/33238184-d8c76990-d2c2-11e7-9e0a-831717ed483e.png" alt="image"></p>
<p>DBSCAN比较麻烦，需要设置合适的参数才能发现正确的类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> KernelPCA</div><div class="line">model = KernelPCA(kernel=<span class="string">"rbf"</span>, fit_inverse_transform=<span class="keyword">True</span>, gamma=<span class="number">10</span>)</div><div class="line">data_transform = model.fit_transform(x)</div><div class="line">label = KMeans(n_clusters=<span class="number">2</span>).fit_predict(data_transform)</div><div class="line">plt.scatter(x[:,<span class="number">0</span>],x[:,<span class="number">1</span>],c=label)</div></pre></td></tr></table></figure>
<p>这里利用了 KPCA 进行升维然后使用 KMeans 进行聚类，效果拔群</p>
<p><img src="https://user-images.githubusercontent.com/10239202/33238189-0cebfe84-d2c3-11e7-900d-8793513586a9.png" alt="image"></p>
<p>做了一段时间的聚类分析，主要用的参数是凝聚度，离散度和轮廓系数，但是这里有一个要注意的地方，其实很多这些指标都是基于簇是类圆形的，<br>对于像上面的那种线性不可分的情况其实不太适用。</p>
<p>总的来说，其实对于高维数据的聚类其实是相当的麻烦的，特别是做无监督的聚类，其评价方法不是很有效。</p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://dong100136.github.io/2017/11/26/kmeans和som的简单比较/" data-id="cjaghmrc20004g8z6r5zuo83g" class="article-share-link">分享到</a><div class="tags"><a href="/tags/聚类/">聚类</a><a href="/tags/机器学习/">机器学习</a></div><div class="post-nav"><a href="/2017/11/05/yiguan-md/" class="pre">基于Spark的用户行为漏斗分析</a></div><div id="uyan_frame"><script src="http://v2.uyan.cc/code/uyan.js?uid=2131915"></script></div></div></div></div><div class="pure-u-1 pure-u-md-1-4"><div id="sidebar"><div class="widget"><form action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="http://dong100136.github.io"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/正则/" style="font-size: 15px;">正则</a> <a href="/tags/docker/" style="font-size: 15px;">docker</a> <a href="/tags/聚类/" style="font-size: 15px;">聚类</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/信息检索/" style="font-size: 15px;">信息检索</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/前端/" style="font-size: 15px;">前端</a> <a href="/tags/js/" style="font-size: 15px;">js</a> <a href="/tags/速查/" style="font-size: 15px;">速查</a> <a href="/tags/javascript/" style="font-size: 15px;">javascript</a> <a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/spark/" style="font-size: 15px;">spark</a> <a href="/tags/rpc/" style="font-size: 15px;">rpc</a> <a href="/tags/emacs/" style="font-size: 15px;">emacs</a> <a href="/tags/大数据/" style="font-size: 15px;">大数据</a> <a href="/tags/数据库/" style="font-size: 15px;">数据库</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a> <a href="/tags/elasticsearch/" style="font-size: 15px;">elasticsearch</a> <a href="/tags/yarn/" style="font-size: 15px;">yarn</a> <a href="/tags/hadoop/" style="font-size: 15px;">hadoop</a> <a href="/tags/scala/" style="font-size: 15px;">scala</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/11/26/kmeans和som的简单比较/">kmeans和som的简单比较</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/05/yiguan-md/">基于Spark的用户行为漏斗分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/04/20/hadoop/【读书笔记】MRv2框架源码解析/">【读书笔记】MRv2框架分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/29/elasticsearch/elasticsearch-索引篇/">elasticsearch-索引篇</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/22/elasticsearch/elasticsearch-角色篇/">elasticsearch-角色篇</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/22/elasticsearch/elasticsearch-基础篇/">elasticsearch-基础篇</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/06/lucene介绍及打分公式说明/">lucene介绍及打分公式说明</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/01/02/akka-basic/">akka学习小记</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/27/spark/spark-tunning-reading-note/">通过测试进行Spark调优</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/12/26/rpc-basic/">基于Socket的rpc简单实践</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://github.com/dong100136" title="github主页" target="_blank">github主页</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">Stone 东少.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>